{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a matrix product operator using singular value decompositions\n",
    "\n",
    "Siddhartha Harmalkar\n",
    "\n",
    "June 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation\n",
    "Algorithm: Given an operator $\\rho_{i,j}$ with indices $i,j\\in\\mathbb Z_d^n$:\n",
    "(<mark>todo: update max bond dimension</mark>)\n",
    "1. Reshape: $\\rho_{i,j}= P_{(i_1\\cdots i_n),(j_1\\cdots j_n)}$ has dimensions $d^n\\times d^n$\n",
    "2. Permute: $P_{(i_1\\cdots i_n),(j_1\\cdots j_n)}= T_{(i_1j_1),\\cdots ,(i_nj_n)}$ has dimensions $d^2\\times\\cdots \\times d^2$ ($n$ times)\n",
    "3. Collect: $T_{(i_1j_1),(i_2j_2\\cdots i_nj_n)}$ has dimensions $d^2\\times d^{2(n-1)}$\n",
    "4. First site:\n",
    "\t- SVD: $T_{(i_1j_1),(i_2j_2\\cdots i_nj_n)}=\\sum_{\\alpha\\in \\mathbb Z_{D_1}} U_{(i_1j_1),\\alpha}S_{\\alpha,\\alpha} (V^\\dagger)_{\\alpha,(i_2j_2\\cdots i_nj_n)}$, where $D_1\\in \\{1,\\cdots,d^2\\}$ is determined by truncation \n",
    "\t- Save: $M^{(1)}_{\\alpha,u,\\beta}=\\delta_{\\alpha,1}U_{u,\\beta}$ has dimensions $1\\times d^2\\times D_1$\n",
    "\t- Update: $T^{(1)}_{(\\alpha i_2j_2),(i_3j_3\\cdots i_nj_n)}=S_{\\alpha,\\alpha}(V^\\dagger)_{\\alpha,(i_2j_2\\cdots i_nj_n)}$ has dimensions $D_1 d^2\\times d^{2(n-2)}$\n",
    "5. Inner sites: For $k\\in \\{2,\\cdots,n-1\\}$:\n",
    "\t- SVD: $T^{(k)}_{(\\alpha i_kj_k),(i_{k+1}j_{k+1}\\cdots i_nj_n)}=\\sum_{\\beta\\in \\mathbb Z_{D_k}} U_{(\\alpha i_kj_k),\\beta}S_{\\beta,\\beta} (V^\\dagger)_{\\beta,(i_{k+1}j_{k+1}\\cdots i_nj_n)}$, where $D_k\\in\\{1,\\cdots,D_{k-1}d^2\\}$\n",
    "\t- Save: $M^{(k)}_{\\alpha,u,\\beta}=U_{(\\alpha u),\\beta}$ has dimensions $D_{k-1}\\times d^2\\times D_k$\n",
    "\t- Update: $T_{(\\alpha i_{k+1}j_{k+1}),(i_{k+2}j_{k+2}\\cdots i_nj_n)}=S_{\\alpha,\\alpha} (V^\\dagger)_{\\alpha,(i_{k+1}j_{k+1}\\cdots i_nj_n)}$ has dimensions $D_k d^2\\times d^{2(n-k-1)}$\n",
    "6. Last site:\n",
    "\t- Save: $M^{(n)}_{\\alpha,u,\\beta}=T^{(n-1)}_{(\\alpha,u),\\beta}$ has dimensions $D_{n-1}\\times d^2\\times 1$ (note that $T^{(n-1)}_{(\\alpha i_nj_n),\\beta}$ has dimensions $D_{n-1} d^2\\times 1$)\n",
    "7. Return $\\{M^{(k)}\\}_{k\\in\\mathbb Z_n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "# Given a density matrix, return its matrix product operator representation\n",
    "# Indices are stored in the following format: (bond,phys,bond)\n",
    "def state_to_mpo(state, n, d, verbose=False, **kwargs):\n",
    "    # If not given a maximum bond dimension, set it to the maximum possible - d^(4n) (TODO)?\n",
    "    #TODO: add a truncation magnitude cuttoff instead of just max_bd\n",
    "    max_bd = kwargs.get('max_bd', d**(4*n))\n",
    "    \n",
    "    # Constructing environment tensor                                                                              \n",
    "    tensor_shape = tuple([d]*(2*n))\n",
    "    tensor = state.reshape(tensor_shape)\n",
    "    tensor_axes = [i for i in range(2*n)]\n",
    "    T_axes = [int(i/2) if i%2 == 0 else int(n + (i/2)) for i in range(2*n)]\n",
    "    d2 = d**2\n",
    "    T = np.moveaxis(tensor, tensor_axes, T_axes)\n",
    "    T = T.reshape((d2,d2**(n-1)))\n",
    "    if verbose:\n",
    "        print(0, \"Initial T:\\t\\t\\t\\t\", T.shape)\n",
    "\n",
    "    # First site\n",
    "    mpo = [0]*n\n",
    "    U, S, Vt = la.svd(T, full_matrices = False)\n",
    "    U = U[:,:max_bd]\n",
    "    S = S[:max_bd]\n",
    "    Vt = Vt[:max_bd,:]\n",
    "    mpo[0] = U.reshape((1,U.shape[0],U.shape[1]))\n",
    "    T = np.dot(np.diag(S),Vt).reshape(S.size*d2,int(Vt.shape[1]/d2))\n",
    "    if verbose:\n",
    "        print(1, U.shape, Vt.shape, \"\\t->\", mpo[0].shape, \"\\t\", T.shape, \"\\t\", S.size)\n",
    "\n",
    "    # Interior sites\n",
    "    for i in range(1,n-1):\n",
    "            U, S, Vt = la.svd(T, full_matrices = False)\n",
    "            U = U[:,:max_bd]\n",
    "            S = S[:max_bd]\n",
    "            Vt = Vt[:max_bd,:]\n",
    "            mpo[i] = U.reshape((int(U.shape[0]/d2),d2,U.shape[1]))\n",
    "            T = np.dot(np.diag(S),Vt).reshape((S.size*d2,int(Vt.shape[1]/d2)))\n",
    "            if verbose:\n",
    "                print(i+1, U.shape, Vt.shape, \"\\t->\", mpo[i].shape, \"\\t\", T.shape, \"\\t\", S.size)\n",
    "\n",
    "    # Last site\n",
    "    mpo[n-1] = np.dot(np.diag(S),Vt).reshape((S.size, Vt.shape[0], 1))\n",
    "    if verbose:\n",
    "        print(n, \"Final Matrix:\\t\\t  \", mpo[n-1].shape)\n",
    "\n",
    "    return mpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this algorithm on a randomly generated density matrix. I should expect to see the following dimensions of my matrices and local tensor after performing each SVD for $d=3,n=5$: The density matrix has dimensions $3^5\\times 3^5$ and the environment tensor $T$ starts out with dimensions $9\\times 9^4$. After each step, we should expect $D_k=9^k$ <mark>(TODO: update this)</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mixed state of randomly sampled pure qudit states                                                 \n",
    "# d - onsite hilbert space dimension\n",
    "# N - number of sites\n",
    "# M - number of pure states used\n",
    "def random_mixed_state(N,d=3,M=10):\n",
    "        states = [random_state(N,d) for i in range(M)]\n",
    "        weights = [np.random.uniform(low=0.0,high=1.0) for i in range(M)]\n",
    "        total_weight = sum(weights)\n",
    "        state = np.zeros((d**N,d**N))\n",
    "        for i in range(M):\n",
    "                state = state + (weights[i]/total_weight) * np.outer(states[i],states[i].conj())\n",
    "        return state\n",
    "\n",
    "# Generate a random qudit state\n",
    "# d - onsite hilbert space dimension\n",
    "# N - number of sites\n",
    "def random_state(N,d=3):\n",
    "        normals = [np.random.standard_normal(size=d**N) for i in range(2)]\n",
    "        state = np.array([normals[0][i] + 1j * normals[1][i] for i in range(d**N)])\n",
    "        state /= la.norm(state)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Initial T:\t\t\t\t (9, 6561)\n",
      "1 (9, 9) (9, 6561) \t-> (1, 9, 9) \t (81, 729) \t 9\n",
      "2 (81, 81) (81, 729) \t-> (9, 9, 81) \t (729, 81) \t 81\n",
      "3 (729, 81) (81, 81) \t-> (81, 9, 81) \t (729, 9) \t 81\n",
      "4 (729, 9) (9, 9) \t-> (81, 9, 9) \t (81, 1) \t 9\n",
      "5 Final Matrix:\t\t   (9, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "n = 5\n",
    "rho = random_mixed_state(n,d)\n",
    "m_rho = state_to_mpo(rho,n,d,verbose=True,max_bd=81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple check of this algorithm is to verify that $\\rho_{ij}=\\rho_{i_1\\cdots i_n j_1\\cdots j_n}=\\rho_{i_1j_1\\cdots i_nj_n}=\\rho_{u_1\\cdots u_n}=\\prod_k \\rho^{(k)u_k}$. Note that $u_k=d * i_k+j_k$ is the most natural mapping, but I'm not sure if that corresponds with the way reshape works (which might be $u_k = i_k + d*j_k$ or something else). Instead of doing this check for a specific index, we can reconstruct $\\rho$ from the MPO $\\rho^{(k)}$ by just multiplying matrices and doing the reshaping outlined above, in reverse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "def mpo_to_state(m):\n",
    "    n = len(m)\n",
    "    _,d,_ = m[0].shape\n",
    "    \n",
    "    state = np.zeros((d**n,d**n))\n",
    "    tensor_shape = tuple([d]*(2*n))\n",
    "    state = state.reshape(tensor_shape)\n",
    "    for i in range(d**(2*n)):\n",
    "        for k in range(n):\n",
    "            index[k] = i/k #TODO: index properly\n",
    "            temp = np.dot(temp,m[:,index[k],:])\n",
    "        state[index] = temp\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner products\n",
    "The Frobenius norm overlap between two operators is defined to be\n",
    "$$\\left<\\rho|\\sigma\\right>=\\mathrm{Tr}\\left[\\rho^\\dagger\\sigma\\right]=d^{-n}\\sum_u \\left(\\prod_i \\rho^{(i)u_i}\\right)^*\\left(\\prod_j \\sigma^{(i)u_j}\\right),$$\n",
    "where $*$ denotes element-wise complex conjugation. This can be calculated in a linear number of computations in $d$ and $n$ and cubic in $D^\\sigma$ and $D^\\rho$ like so:\n",
    "1. $M_{\\alpha\\beta} = \\sum_{u\\in \\mathbb Z_d}(\\rho^{(1)}_{1u\\alpha})^*\\sigma^{(1)}_{1u\\beta}$\n",
    "2. For $k\\in\\{2,\\cdots,n\\}:$\n",
    "    - $M_{\\alpha\\beta}\\leftarrow \\sum_{u\\in \\mathbb Z_d,\\mu\\in\\mathbb Z_{D^\\rho_k},\\mu\\in\\mathbb Z_{D^\\sigma_k}}(\\rho^{(k)}_{\\mu u \\alpha})^*M_{\\mu \\nu}\\sigma^{(k)}_{\\nu u \\beta}$\n",
    "3. Return $M_{11}$\n",
    "\n",
    "Note that the matrix elements are stored like so: $\\rho^{(1)u}_{\\alpha\\beta}=\\rho_{\\alpha u \\beta}$, and $D^\\rho_k$ denotes the bond dimension of $\\rho$'s MPO at site $k$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap between two MPOs\n",
    "# Assumptions:\n",
    "#       len(m1) = len(m2)                                       [same length]\n",
    "#       m1[i].shape = m2[i].shape = (bond,phys,bond)            [same bond and phys dim at each site]\n",
    "#       m1[0].shape = (1,_,_) and m1[-1].shape = (_,_,1)        [closed boundary conditions]\n",
    "def overlap(m1, m2):\n",
    "        # Extract length, phys dim, and first site bond dim\n",
    "        n = len(m1)\n",
    "\n",
    "        # First site\n",
    "        M = np.tensordot(m1[0][0].conj(),m2[0][0],axes=([0,0]))      # sum over physical indices\n",
    "\n",
    "        #print(0,m1[0].shape,M.shape)\n",
    "        # Rest of contraction\n",
    "        for i in range(1,n):\n",
    "                M = np.tensordot(M,m1[i].conj(),axes=([0,0]))\n",
    "                M = np.tensordot(M,m2[i],axes=([0,1],[0,1]))\n",
    "                #print(i,m1[i].shape, M.shape)\n",
    "        return M[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test: For the random state $\\rho$, does $\\mathrm{Tr}[\\rho^\\dagger \\rho]=\\left<\\{\\rho^{(k)}\\}|\\{\\rho^{(k)}\\}\\right>$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.12005490874249065+0j)\n",
      "(0.1200549087424906+8.673617379884035e-19j)\n"
     ]
    }
   ],
   "source": [
    "print(np.trace(np.dot(rho.T.conj(),rho)))\n",
    "print(overlap(m_rho,m_rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test: Given random states $\\rho$ and $\\sigma$, $\\mathrm{Tr}[\\rho^\\dagger \\sigma]=\\left<\\{\\rho^{(k)}\\}|\\{\\sigma^{(k)}\\}\\right>$. Does the contraction algorithm give a similar result (and work at all) when $\\{\\sigma^{(k)}\\}$ are generated with some singular values truncated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.004206078770536007+1.8973538018496328e-19j)\n",
      "(0.00420607877053601+2.439454888092385e-19j)\n",
      "(0.0035503599462803634-3.709388152946339e-05j)\n"
     ]
    }
   ],
   "source": [
    "sigma_same_bd = random_mixed_state(n,d)\n",
    "m_sigma = state_to_mpo(sigma,n,d)\n",
    "m_sigma_smaller = state_to_mpo(sigma,n,d,max_bd=50)\n",
    "print(np.trace(np.dot(rho.T.conj(),sigma)))\n",
    "print(overlap(m_rho,m_sigma))\n",
    "print(overlap(m_rho,m_sigma_smaller))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test: Given a random state $\\rho$ and an MPO for the identity matrix, does the overlap of the states give 1 due to normalization of $\\rho$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9999999999999999+8.732788471021416e-17j)\n"
     ]
    }
   ],
   "source": [
    "max_mixed = np.identity(d**n)\n",
    "m_max = state_to_mpo(max_mixed,n,d)\n",
    "print(overlap(m_rho,m_max))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
